{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder, RobustScaler, StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV \n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_edge_dataset(file_path):\n",
    "    # Loading the data\n",
    "    Raw_Data = pd.read_csv(file_path, low_memory=False)\n",
    "    # Fixing the fault in 'arp.hw.size' where 'frame.time' equals '6.0'\n",
    "    idx_hw_6 = Raw_Data[Raw_Data['frame.time'] == '6.0'].index\n",
    "    Raw_Data.loc[idx_hw_6, 'arp.hw.size'] = 6.0  # Fix the value to 6.0\n",
    "    # Droping unnecessary columns by index\n",
    "    Columns_to_drop = [0, 1, 2, 3, 6, 9, 10, 11, 13, 16, 19, 27, 31, 32, 34, 35, 50, 51, 54, 55, 59, 60]\n",
    "    Raw_Data = Raw_Data.drop(Raw_Data.columns[Columns_to_drop], axis=1)\n",
    "    # Removing target labels\n",
    "    attack_label = Raw_Data.pop('Attack_label') if 'Attack_label' in Raw_Data else None\n",
    "    attack_type = Raw_Data.pop('Attack_type') if 'Attack_type' in Raw_Data else None\n",
    "    # Replacing categorical feature values as specified\n",
    "    categorical_features = ['http.request.method', 'http.referer', 'http.request.version', 'dns.qry.name.len', 'mqtt.conack.flags']\n",
    "    for feature in categorical_features:\n",
    "        Raw_Data[feature] = Raw_Data[feature].replace('0', '0.0')\n",
    "    # mapping Attack_type to 6 numerical values\n",
    "    mapping_dict = {'DDoS_UDP': 1, 'DDoS_ICMP': 1, 'DDoS_HTTP': 1, 'DDoS_TCP': 1,\n",
    "                'Port_Scanning': 2, 'Fingerprinting': 2, 'Vulnerability_scanner': 2,\n",
    "                'MITM' : 3, 'XSS' : 4, 'SQL_injection': 4, 'Uploading':4, \n",
    "                'Backdoor': 5, 'Password': 5, 'Ransomware':5, 'Normal':6}\n",
    "    attack_type = attack_type.map(mapping_dict)\n",
    "    # Removing Duplicates\n",
    "    duplicate_index = Raw_Data.duplicated()\n",
    "    Raw_Data = Raw_Data[~duplicate_index]\n",
    "    Raw_Data, attack_label, attack_type = Raw_Data[~duplicate_index], attack_label[~duplicate_index], attack_type[~duplicate_index]\n",
    "\n",
    "    return Raw_Data, attack_label, attack_type\n",
    "\n",
    "file_path = \"../Data/ML-EdgeIIoT-dataset.csv\"\n",
    "Data, Attack_label, Attack_type = preprocess_edge_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample reduction transformer for Pipeline\n",
    "class SampleSubsetSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_train_samples=6000):\n",
    "        self.max_train_samples = max_train_samples\n",
    "        self.is_train = True  # Default to training mode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting necessary for this transformer\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.is_train and y is not None:\n",
    "            if len(X) > self.max_train_samples:\n",
    "                X, _, y, _ = train_test_split(X, y, train_size=self.max_train_samples, stratify=y, random_state=22)       \n",
    "        return (X, y) if y is not None else X\n",
    "\n",
    "    def set_is_train(self, is_train=True):\n",
    "        self.is_train = is_train\n",
    "\n",
    "# Export Function\n",
    "def export_model(model_name, model, binary:bool):\n",
    "    if binary:\n",
    "        X_train, _, Y_train, _ = train_test_split(Data, Attack_label, train_size=20000, test_size=100000, random_state=22, stratify= Attack_type)\n",
    "    else:\n",
    "        X_train, _, Y_train, _ = train_test_split(Data, Attack_type, train_size=20000, test_size=100000, random_state=22, stratify= Attack_type)\n",
    "    model.fit(X_train, Y_train)\n",
    "    with open(f'../Docker/data/{model_name}_model.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "# Binary classifiers evaluation\n",
    "def evaluate_bin(model_name, test: np.ndarray, pred: np.ndarray, display:bool = True):\n",
    "    if model_name == 'LOF':\n",
    "        test_novel = np.where(test == 0, -1, 1)\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(test_novel, pred, labels=[1,-1]).ravel()\n",
    "        df_metric = pd.DataFrame({'Average Accuracy Score': metrics.accuracy_score(test_novel, pred)*100,                              \n",
    "                                'Precision':metrics.precision_score(test_novel, pred, pos_label= -1, average = 'binary')*100,\n",
    "                                'Recall': metrics.recall_score(test_novel, pred, pos_label= -1, average = 'binary')*100,\n",
    "                                'F1-Score': metrics.f1_score(test_novel, pred, pos_label= -1, average = 'binary' )*100,\n",
    "                                'FPR':(fp/(tn+fp))*100},\n",
    "                                index= ['Anomaly'])\n",
    "        if display:\n",
    "            metrics.ConfusionMatrixDisplay.from_predictions(test_novel, pred, display_labels=['Normal', 'Anomaly'], normalize= 'true')\n",
    "            plt.title(model_name)\n",
    "    else:\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix(test, pred, labels=[0,1]).ravel()\n",
    "        df_metric = pd.DataFrame({'Average Accuracy Score': metrics.accuracy_score(test, pred)*100,                              \n",
    "                                'Precision':metrics.precision_score(test, pred, pos_label= 1, average = 'binary')*100,\n",
    "                                'Recall': metrics.recall_score(test, pred, pos_label= 1, average = 'binary')*100,\n",
    "                                'F1-Score': metrics.f1_score(test, pred, pos_label= 1, average = 'binary' )*100,\n",
    "                                'FPR':(fp/(tn+fp))*100}, \n",
    "                                index= ['Anomaly'])\n",
    "        if display:\n",
    "            metrics.ConfusionMatrixDisplay.from_predictions(test, pred, display_labels=['Normal', 'Anomaly'], normalize= 'true')\n",
    "            plt.title(model_name)\n",
    "    return df_metric\n",
    "\n",
    "# multiclass classifiers evaluation\n",
    "def evaluate_clf(model_name, test: np.ndarray, pred: np.ndarray, display:bool = True):\n",
    "    df_metric = pd.DataFrame({'Accuracy': metrics.accuracy_score(test, pred),\n",
    "                              'Precison': metrics.precision_score(test, pred, average= None),\n",
    "                              'Recall': metrics.recall_score(test, pred, average= None),\n",
    "                              'F1-Score': metrics.f1_score(test, pred, average= None)\n",
    "                            }, index= [1,2,3,4,5,6])\n",
    "    if display:\n",
    "        metrics.ConfusionMatrixDisplay.from_predictions(test, pred, values_format= 'd')# normalize= None)\n",
    "        plt.title(model_name)\n",
    "    return df_metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoders and Scalers\n",
    "categorical_features = Data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = Data.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "numerical_transformer_rob = RobustScaler()\n",
    "numerical_transformer_std = StandardScaler()\n",
    "categorical_transformer_tar = TargetEncoder()\n",
    "\n",
    "transformer_rob_tar = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Robust Scaling numerical features', numerical_transformer_rob, numerical_features), # robust scaling\n",
    "        ('Target Encoding categorical features', categorical_transformer_tar, categorical_features) # target encoding\n",
    "    ])\n",
    "transformer_pass_tar = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('passthrough numerical features', 'passthrough', numerical_features), # passthrough\n",
    "        ('Target Encoding categorical features', categorical_transformer_tar, categorical_features) # target encoding\n",
    "    ])\n",
    "\n",
    "# Pipelines Binaries\n",
    "Pipeline_SVC = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(2500)),\n",
    "    ('transformer', transformer_pass_tar),\n",
    "    ('scale', StandardScaler()),        \n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', SVC(kernel='poly', C= 1, degree= 3, probability= True))\n",
    "    ])\n",
    "\n",
    "Pipeline_KNN = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(2500)),\n",
    "    ('transformer', transformer_rob_tar),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', KNeighborsClassifier(leaf_size= 2, n_neighbors= 2, p= 1, weights= 'distance'))\n",
    "    ])\n",
    "\n",
    "Pipeline_RF = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(8000)),\n",
    "    ('transformer', transformer_rob_tar),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', RandomForestClassifier(criterion= 'gini', max_depth= None, max_features= 0.4, max_samples= 0.4, n_estimators= 80))\n",
    "    ])\n",
    "\n",
    "Pipeline_LOF = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(6000)),\n",
    "    ('transformer', transformer_rob_tar),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', LocalOutlierFactor(novelty= True, leaf_size= 6, metric= 'manhattan', n_neighbors= 2))\n",
    "    ])\n",
    "\n",
    "Vote_bin_clf = VotingClassifier(estimators=[('SVC', Pipeline_SVC), ('KNN', Pipeline_KNN), ('RF', Pipeline_RF)], voting='soft')\n",
    "\n",
    "# Pipelines Multiclass classifiers\n",
    "Pipeline_mult_SVC = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(max_train_samples= 4000)),\n",
    "    ('transformer', transformer_pass_tar),\n",
    "    ('scale', StandardScaler()),        \n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', SVC(decision_function_shape='ovo', kernel='rbf', C= 1e4, probability=True))\n",
    "    ])\n",
    "\n",
    "Pipeline_mult_LinSVC = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(max_train_samples= 4000)),\n",
    "    ('transformer', transformer_pass_tar),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', CalibratedClassifierCV(LinearSVC(dual= 'auto', max_iter= 1500, fit_intercept= False, loss= 'squared_hinge', penalty= 'l2', C= 30)))\n",
    "    ])\n",
    "\n",
    "Pipeline_mult_KNN = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(max_train_samples= 10000)),\n",
    "    ('transformer', transformer_rob_tar),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', KNeighborsClassifier(leaf_size= 2, n_neighbors= 2, p= 1, weights= 'distance'))\n",
    "    ])\n",
    "\n",
    "Pipeline_mult_RF = Pipeline([\n",
    "    ('subsample', SampleSubsetSelector(max_train_samples= 8000)),\n",
    "    ('transformer', transformer_rob_tar),\n",
    "    ('smote', SMOTEENN(random_state= 22)),\n",
    "    ('model', RandomForestClassifier(criterion= 'entropy', max_depth= 10, max_features= 0.8, max_samples= 0.8, n_estimators= 80))\n",
    "    ])\n",
    "\n",
    "Vote_mult_clf = VotingClassifier(estimators=[('SVC', Pipeline_mult_SVC), ('KNN', Pipeline_mult_KNN), ('RF', Pipeline_mult_RF), ('LinearSVC', Pipeline_mult_LinSVC)], voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model('RF', Pipeline_RF, binary= True)\n",
    "export_model('RF_Multi', Pipeline_mult_RF, binary= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model('Vote', Vote_bin_clf, binary= True)\n",
    "export_model('Vote_Multi', Vote_mult_clf, binary= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Pipeline_mult_RF\n",
    "test_model_name = 'RF_Multi'\n",
    "\n",
    "with open(f'../Docker/data/{test_model_name}_model.pkl', 'rb') as f:\n",
    "    model_pkl = pickle.load(f)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(Data, Attack_type, train_size=20000, test_size=100000, random_state=22, stratify= Attack_type)\n",
    "\n",
    "test_model.fit(X_train, Y_train)\n",
    "\n",
    "# Testing\n",
    "Y_pred = test_model.predict(X_test)\n",
    "print(evaluate_clf(test_model_name, Y_test, Y_pred))\n",
    "\n",
    "Y_pred = model_pkl.predict(X_test)\n",
    "print(evaluate_clf('model_pkl', Y_test, Y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
